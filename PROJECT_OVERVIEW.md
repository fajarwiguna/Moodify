# üéß AI Mood-to-Music Recommender: Project Overview

## üìå Project Summary

The **AI Mood-to-Music Recommender** is a web-based application that detects a user's emotions from a selfie or uploaded photo and recommends a Spotify playlist tailored to their mood. By combining computer vision, machine learning, and Spotify's API, this project creates a fun, interactive, and personalized music experience. It serves as a portfolio piece to showcase skills in machine learning, API integration, and clean software engineering practices.

## üéØ Goals

- **Portfolio Showcase**: Demonstrate expertise in computer vision (CV), machine learning (ML), API integration, and web development.
- **Engaging User Experience**: Provide a fun, interactive application that connects emotions to music.
- **Professional Documentation**: Include clear documentation and a live demo to impress recruiters and technical audiences.

## ‚ú® Key Features (MVP)

- **Photo Upload/Webcam Input**: Users can upload a photo or take a selfie via webcam.
- **Facial Emotion Detection**: Utilizes the DeepFace library to detect emotions (e.g., happy, sad, angry, neutral, surprised).
- **Mood-to-Music Mapping**: Maps detected emotions to curated music genres or playlists.
- **Spotify Playlist Recommendations**: Integrates with Spotify API to deliver mood-based playlists.
- **Responsive UI**: Built with Streamlit for an intuitive and interactive interface.

## üõ†Ô∏è Tech Stack

| Area                 | Tools/Libraries                     |
|----------------------|-------------------------------------|
| Frontend/UI          | Streamlit                           |
| Emotion Detection    | DeepFace, OpenCV                    |
| Music API            | Spotify Web API, Spotipy            |
| Backend              | Python                              |
| Deployment           | Hugging Face Spaces/Streamlit Cloud |
| Documentation        | Markdown, draw.io (diagrams)        |

## üöÄ Why It Stands Out

- **Interactive Demo**: A live link allows users to try the app with their own selfies.
- **Multidisciplinary**: Combines CV, ML, and API integration for a unique portfolio piece.
- **Fun & Relatable**: Connects AI with everyday music listening.
- **Professional Documentation**: Includes README, Model Card, and architecture diagrams for credibility.

## üìà MVP Scope (1 Week)

- [x] Photo/webcam upload functionality.
- [x] Emotion detection using a pre-trained DeepFace model.
- [x] Simple mood-to-music mapping logic.
- [x] Spotify API integration with curated playlists.
- [x] Streamlit UI and deployment.
- [ ] Comprehensive documentation (README, Model Card, architecture diagram).

## üîÆ Future Enhancements

- Real-time webcam emotion detection.
- Personalized playlists based on user listening history.
- Enhanced UI with animations and mobile responsiveness.
- Improved emotion detection with custom models.

## üìÇ Next Steps

1. Create a GitHub repository with the [folder structure](#project-folder-structure).
2. Develop the MVP (see [roadmap](#roadmap)).
3. Deploy to Hugging Face Spaces or Streamlit Cloud.
4. Share the project on LinkedIn with a demo link and insights.